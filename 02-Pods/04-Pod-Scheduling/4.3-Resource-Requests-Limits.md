# **5.3 Resource Requests and Limits**

- **Requests** are the resources that are guaranteed to be available to the container. They influence where the Pod is scheduled (which node it runs on).

- **Limits** are the maximum resources the container can use. If the container exceeds these limits, it may be throttled (for CPU) or killed (for memory).

## **1. Resource Requests**

**Resource Requests** specify the minimum amount of CPU and memory that a Pod needs to run. The Kubernetes scheduler uses these requests to determine which node can best accommodate the Pod based on the available resources.

- **CPU Requests**: Measured in CPU units, where 1 CPU unit corresponds to one physical CPU core. A request of `0.5` means the Pod requires half a CPU core.
- **Memory Requests**: Measured in bytes (or using suffixes like `Mi` for mebibytes, `Gi` for gibibytes). A request of `256Mi` means the Pod requires 256 MiB of memory.

When the scheduler places a Pod on a node, it ensures that the node has at least the amount of resources specified by the requests.

**Example of Resource Requests**:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
    - name: my-container
      image: nginx
      resources:
        requests:
          memory: "256Mi"
          cpu: "0.5"
```

In this example:

- The `my-container` requests `256Mi` of memory and `0.5` CPU units.

## **2. Resource Limits**

**Resource Limits** specify the maximum amount of CPU and memory that a Pod is allowed to use. If a Pod tries to use more than the specified limit, it may be throttled (for CPU) or evicted (for memory) depending on the situation.

- **CPU Limits**: When a Pod exceeds its CPU limit, Kubernetes throttles the Pod's CPU usage, ensuring it doesn't consume more than its limit.
- **Memory Limits**: If a Pod exceeds its memory limit, it can be terminated and restarted by the Kubernetes system to free up resources.

**Example of Resource Limits**:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
    - name: my-container
      image: nginx
      resources:
        limits:
          memory: "512Mi"
          cpu: "1"
```

In this example:

- The `my-container` is limited to using a maximum of `512Mi` of memory and `1` CPU unit.

## **3. Combining Resource Requests and Limits**

You typically specify both requests and limits for each container within a Pod to provide a range of acceptable resource usage. Requests ensure that the Pod has enough resources to run, while limits prevent the Pod from over-consuming resources.

**Example of Combined Resource Requests and Limits**:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
    - name: my-container
      image: nginx
      resources:
        requests:
          memory: "256Mi"
          cpu: "0.5"
        limits:
          memory: "512Mi"
          cpu: "1"
```

In this example:

- The `my-container` requests `256Mi` of memory and `0.5` CPU units but is limited to `512Mi` of memory and `1` CPU unit.

## **4. Resource Overcommitment and QoS Classes**

**Resource Overcommitment** occurs when the sum of resource requests across all Pods on a node exceeds the node's total capacity. Kubernetes allows this to some extent, relying on the fact that not all Pods will use their requested resources simultaneously.

**Quality of Service (QoS) Classes** are assigned to Pods based on their resource requests and limits:

1. **Guaranteed**: Pods that have equal requests and limits for all resources (e.g., `cpu` and `memory`). These Pods are guaranteed the resources they request and will not be evicted unless the node fails.
2. **Burstable**: Pods that have resource requests but their limits are higher than their requests. These Pods get priority over BestEffort Pods but can still be throttled or evicted if resources are constrained.
3. **BestEffort**: Pods that have no resource requests or limits specified. These Pods have the lowest priority and are the first to be throttled or evicted in case of resource contention.

## **5. Best Practices**

- **Set Realistic Requests**: Ensure that resource requests are based on actual usage patterns to avoid underutilizing nodes or causing scheduling issues.
- **Avoid Overcommitting**: Monitor your cluster to ensure that overcommitting resources doesn't lead to performance degradation.
- **Use Limits Cautiously**: While limits protect against resource overuse, they can also lead to throttling or eviction if set too low, which may affect application performance.
- **Monitor Resource Usage**: Regularly monitor resource usage to adjust requests and limits as needed to ensure optimal cluster performance.

Would you like to continue with another topic, or do you have any questions on what we've covered?
