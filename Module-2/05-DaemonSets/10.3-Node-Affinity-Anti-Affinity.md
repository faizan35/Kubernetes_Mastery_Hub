# Node Selectors, Node Affinity Rules and Anti-Affinity Rules

- You can define **node selectors**, **node affinity**, or **anti-affinity** rules to control which nodes the DaemonSet pods are scheduled on.
- This gives you fine-grained control over pod placement based on node characteristics or other factors.

1.  **Node Selectors**:

    - Node selectors help you pick which nodes your pod should run by using labels.
    - When setting up a DaemonSet, you can use node selectors to say which nodes should host the pods by specifying certain labels.
    - For example, you might label certain nodes as **"storage=true"** and then specify a node selector in your DaemonSet to ensure that only nodes with the label **"storage=true"** host the DaemonSet pods.

2.  **Node Affinity**:

    - Node Affinity allows you to decide where your pod should run based on more specific conditions, like node labels or other pod attributes.
    - When configuring a DaemonSet, Node Affinity lets you control which nodes should host the pods by defining these conditions.

    - Node affinity can be either **"required"** or **"preferred"**.
      - "Required" node affinity means the pods must go where specified.
      - "Preferred" node affinity suggests where the pods should go, but it's okay if conditions aren't met (means, Kubernetes will still schedule the pods on other available nodes).

3.  **Anti-Affinity**:

    - Anti-affinity is the opposite of affinity. It allows you to prevent pods from being scheduled on nodes that meet certain conditions.
    - You can specify anti-affinity rules to ensure that DaemonSet pods are not scheduled on nodes that already have pods meeting certain criteria.
    - This is useful for scenarios where you want to spread out your pods across different nodes for resilience or performance reasons.

4.  **Example Use Cases**:

    - **Node Selector**: You might use a node selector to ensure that DaemonSet pods requiring GPU resources are only scheduled on nodes with GPUs.
    - **Node Affinity**: You could use node affinity to ensure that DaemonSet pods running database replicas are scheduled on nodes with SSD storage.
    - **Anti-Affinity**: You could employ anti-affinity rules to ensure that DaemonSet pods running critical services are not scheduled on nodes hosting other critical services to prevent a single point of failure.

### Table

| Feature        | Node Selector                                                     | Node Affinity                                                                                                            | Anti-Affinity                                                             |
| -------------- | ----------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------- |
| Purpose        | Filters nodes based on labels.                                    | Defines rules for pod placement based on node labels or other attributes.                                                | Prevents pods from being scheduled on nodes that meet certain conditions. |
| Similarities   | All influence pod scheduling based on node properties.            | All are used to control pod placement in Kubernetes.                                                                     | All contribute to scheduling and placement decisions.                     |
| Differences    | Simple mechanism, filters nodes based on labels.                  | More advanced feature, allows complex rules based on node labels, the presence of other pods, or custom node attributes. | Prevents co-location of pods with certain characteristics.                |
| Flexibility    | Limited flexibility, basic filtering capabilities.                | Greater flexibility, supports complex scheduling requirements.                                                           | Provides additional constraints to influence pod placement.               |
| Use Cases      | Basic scenarios where straightforward node filtering is required. | Complex scenarios requiring fine-grained control over pod placement.                                                     | Ensuring fault tolerance, improving performance, or spreading workloads.  |
| Implementation | Specified using the `nodeSelector` field in pod specifications.   | Specified using the `affinity` field in pod specifications.                                                              | Specified using the `podAntiAffinity` field in pod specifications.        |
| Example        | `nodeSelector: zone: us-west`                                     | Below                                                                                                                    | Below                                                                     |

### Example

#### Node Affinity

```bash
affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
      - matchExpressions:
        - key: "zone"
          operator: In
          values:
          - "us-west"
```

#### Anti-Affinity

```bash
podAntiAffinity:
  requiredDuringSchedulingIgnoredDuringExecution:
  - labelSelector:
      matchExpressions:
      - key: "app"
        operator: In
        values:
        - "example-app"
    topologyKey: "kubernetes.io/hostname"
```
